<!DOCTYPE html>
<html lang="en">
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  
    <title>Regret Analysis of FTRL and OMD Algorithms :: Terminal</title>
  
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="Regret Analysis of FTRL and OMD Algorithms Introduction In this note, we&rsquo;ll explore the regret analysis of both the Follow-The-Regularized-Leader (FTRL) algorithm and the Online Mirror Descent (OMD) algorithm. We&rsquo;ll highlight their similarities and differences, and demonstrate how, under certain conditions, they are essentially equivalent. This analysis includes detailed derivations and mathematical expressions.
Follow-The-Regularized-Leader (FTRL) Problem Setup Consider an online convex optimization problem over ( T ) rounds. At each round ( t ):
" />
<meta name="keywords" content="" />

  <meta name="robots" content="noodp" />

<link rel="canonical" href="http://localhost:1313/blog/2024/ftrl-and-omd/" />





  
  <link rel="stylesheet" href="http://localhost:1313/css/buttons.min.2bc533403a27dfe0e93105a92502b42ce4587e2e4a87d9f7d349e51e16e09478.css">

  
  <link rel="stylesheet" href="http://localhost:1313/css/code.min.00125962708925857e7b66dbc58391d55be1191a3d0ce2034de8c9cd2c481c36.css">

  
  <link rel="stylesheet" href="http://localhost:1313/css/fonts.min.4881f0c525f3ce2a1864fb6e96676396cebe1e6fcef1933e8e1dde7041004fb5.css">

  
  <link rel="stylesheet" href="http://localhost:1313/css/footer.min.2e3eb191baee58dd05a9f0104ac1fab0827bca7c64dafe0b2579f934c33a1d69.css">

  
  <link rel="stylesheet" href="http://localhost:1313/css/gist.min.a751e8b0abe1ba8bc53ced52a38b19d8950fe78ca29454ea8c2595cf26aad5c0.css">

  
  <link rel="stylesheet" href="http://localhost:1313/css/header.min.b6fb4423cf82a9f9d7abc9cd010223fa3d70a6526a3f28f8e17d814c06e18f9e.css">

  
  <link rel="stylesheet" href="http://localhost:1313/css/main.min.fe8dc560fccb53a458b0db19ccb7b265764ac46b68596b7e099c6793054dd457.css">

  
  <link rel="stylesheet" href="http://localhost:1313/css/menu.min.83637a90d903026bc280d3f82f96ceb06c5fc72b7c1a8d686afb5bbf818a29f7.css">

  
  <link rel="stylesheet" href="http://localhost:1313/css/pagination.min.82f6400eae7c7c6dc3c866733c2ec0579e4089608fea69400ff85b3880aa0d3c.css">

  
  <link rel="stylesheet" href="http://localhost:1313/css/post.min.fc74ca360273c1d828da3c02b8174eba435607b369d98418ccc6f2243cd4e75d.css">

  
  <link rel="stylesheet" href="http://localhost:1313/css/prism.min.9023bbc24533d09e97a51a0a42a5a7bfe4c591ae167c5551fb1d2191d11977c0.css">

  
  <link rel="stylesheet" href="http://localhost:1313/css/syntax.min.cc789ed9377260d7949ea4c18781fc58959a89287210fe4edbff44ebfc1511b6.css">

  
  <link rel="stylesheet" href="http://localhost:1313/css/terminal.min.dd0bf9c7cacb24c1b0184f52f1869b274e06689557468cc7030ccf632328eb97.css">

  
  <link rel="stylesheet" href="http://localhost:1313/css/terms.min.b81791663c3790e738e571cdbf802312390d30e4b1d8dc9d814a5b5454d0ac11.css">







<link rel="shortcut icon" href="http://localhost:1313/favicon.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">


<meta name="twitter:card" content="summary" />

  
    <meta name="twitter:site" content="" />
  
    <meta name="twitter:creator" content="Sihan Wei" />



<meta property="og:locale" content="en" />
<meta property="og:type" content="article" />
<meta property="og:title" content="Regret Analysis of FTRL and OMD Algorithms">
<meta property="og:description" content="Regret Analysis of FTRL and OMD Algorithms Introduction In this note, we&rsquo;ll explore the regret analysis of both the Follow-The-Regularized-Leader (FTRL) algorithm and the Online Mirror Descent (OMD) algorithm. We&rsquo;ll highlight their similarities and differences, and demonstrate how, under certain conditions, they are essentially equivalent. This analysis includes detailed derivations and mathematical expressions.
Follow-The-Regularized-Leader (FTRL) Problem Setup Consider an online convex optimization problem over ( T ) rounds. At each round ( t ):
" />
<meta property="og:url" content="http://localhost:1313/blog/2024/ftrl-and-omd/" />
<meta property="og:site_name" content="Terminal" />

  <meta property="og:image" content="http://localhost:1313/og-image.png">

<meta property="og:image:width" content="1200">
<meta property="og:image:height" content="627">

  <meta property="article:section" content="Research" />


  <meta property="article:published_time" content="2024-10-18 22:54:24 -0400 EDT" />












</head>
<body>


<div class="container">

  <header class="header">
  <div class="header__inner">
    <div class="header__logo">
      <a href="/">
  <div class="logo">
    Terminal
  </div>
</a>

    </div>
    
      <ul class="menu menu--mobile">
  <li class="menu__trigger">Menu&nbsp;▾</li>
  <li>
    <ul class="menu__dropdown">
      
        
          <li><a href="/bbs/">BBS</a></li>
        
      
        
          <li><a href="/about/">About</a></li>
        
      
        
          <li><a href="/about">About</a></li>
        
      
        
          <li><a href="/showcase">Showcase</a></li>
        
      
      
    </ul>
  </li>
</ul>

    
    
  </div>
  
    <nav class="navigation-menu">
  <ul class="navigation-menu__inner menu--desktop">
    
      
        
          <li><a href="/bbs/" >BBS</a></li>
        
      
        
          <li><a href="/about/" >About</a></li>
        
      
      
        <li>
          <ul class="menu">
            <li class="menu__trigger">Show more&nbsp;▾</li>
            <li>
              <ul class="menu__dropdown">
                
                  
                    <li><a href="/about" >About</a></li>
                  
                
                  
                    <li><a href="/showcase" >Showcase</a></li>
                  
                
              </ul>
            </li>
          </ul>
        </li>
      
    
  </ul>
</nav>

  
</header>


  <div class="content">
    
<article class="post">
  <h1 class="post-title">
    <a href="http://localhost:1313/blog/2024/ftrl-and-omd/">Regret Analysis of FTRL and OMD Algorithms</a>
  </h1>
  <div class="post-meta"><time class="post-date">2024-10-18</time><span class="post-author">Sihan Wei</span></div>

  
    <span class="post-tags">
      
      #<a href="http://localhost:1313/tags/online-learning/">online learning</a>&nbsp;
      
      #<a href="http://localhost:1313/tags/optimization/">optimization</a>&nbsp;
      
    </span>
  
  


  

  <div class="post-content"><div>
        <h1 id="regret-analysis-of-ftrl-and-omd-algorithms">Regret Analysis of FTRL and OMD Algorithms<a href="#regret-analysis-of-ftrl-and-omd-algorithms" class="hanchor" ariaLabel="Anchor">#</a> </h1>
<h2 id="introduction">Introduction<a href="#introduction" class="hanchor" ariaLabel="Anchor">#</a> </h2>
<p>In this note, we&rsquo;ll explore the regret analysis of both the <strong>Follow-The-Regularized-Leader (FTRL)</strong> algorithm and the <strong>Online Mirror Descent (OMD)</strong> algorithm. We&rsquo;ll highlight their similarities and differences, and demonstrate how, under certain conditions, they are essentially equivalent. This analysis includes detailed derivations and mathematical expressions.</p>
<h2 id="follow-the-regularized-leader-ftrl">Follow-The-Regularized-Leader (FTRL)<a href="#follow-the-regularized-leader-ftrl" class="hanchor" ariaLabel="Anchor">#</a> </h2>
<h3 id="problem-setup">Problem Setup<a href="#problem-setup" class="hanchor" ariaLabel="Anchor">#</a> </h3>
<p>Consider an online convex optimization problem over ( T ) rounds. At each round ( t ):</p>
<ol>
<li><strong>Decision Making</strong>: The learner selects ( \mathbf{x}_t \in \mathcal{X} \subseteq \mathbb{R}^n ).</li>
<li><strong>Loss Revealing</strong>: An adversary reveals a convex loss function ( f_t : \mathcal{X} \rightarrow \mathbb{R} ).</li>
<li><strong>Loss Incurred</strong>: The learner incurs loss ( f_t(\mathbf{x}_t) ).</li>
</ol>
<p><strong>Goal</strong>: Minimize the cumulative <strong>regret</strong>:</p>
<p>[
\text{Regret}<em>T = \sum</em>{t=1}^T f_t(\mathbf{x}<em>t) - \min</em>{\mathbf{x} \in \mathcal{X}} \sum_{t=1}^T f_t(\mathbf{x}).
]</p>
<h3 id="ftrl-algorithm">FTRL Algorithm<a href="#ftrl-algorithm" class="hanchor" ariaLabel="Anchor">#</a> </h3>
<p>At each round ( t ), the FTRL algorithm updates the decision by solving:</p>
<p>[
\mathbf{x}<em>t = \arg\min</em>{\mathbf{x} \in \mathcal{X}} \left{ \eta \sum_{s=1}^{t-1} f_s(\mathbf{x}) + R(\mathbf{x}) \right},
]</p>
<p>where:</p>
<ul>
<li>( \eta &gt; 0 ) is the learning rate.</li>
<li>( R : \mathcal{X} \rightarrow \mathbb{R} ) is a strongly convex regularization function.</li>
</ul>
<h3 id="regret-analysis">Regret Analysis<a href="#regret-analysis" class="hanchor" ariaLabel="Anchor">#</a> </h3>
<p><strong>Assumptions</strong></p>
<ol>
<li><strong>Convexity</strong>: Each loss function ( f_t ) is convex.</li>
<li><strong>Lipschitz Continuity</strong>: The subgradients are bounded: ( | \nabla f_t(\mathbf{x}) |_* \leq G ) for all ( \mathbf{x} \in \mathcal{X} ).</li>
<li><strong>Strong Convexity</strong>: The regularizer ( R ) is ( \lambda )-strongly convex with respect to a norm ( | \cdot | ).</li>
</ol>
<p><strong>Key Steps</strong></p>
<ol>
<li>
<p><strong>One-Step Regret Bound</strong></p>
<p>Using the convexity of ( f_t ):</p>
<p>[
f_t(\mathbf{x}_t) - f_t(\mathbf{x}^<em>) \leq \langle \nabla f_t(\mathbf{x}_t), \mathbf{x}_t - \mathbf{x}^</em> \rangle,
]</p>
<p>where ( \mathbf{x}^* = \arg\min_{\mathbf{x} \in \mathcal{X}} \sum_{t=1}^T f_t(\mathbf{x}) ).</p>
</li>
<li>
<p><strong>Regret Decomposition</strong></p>
<p>Summing over ( t ):</p>
<p>[
\text{Regret}<em>T \leq \sum</em>{t=1}^T \langle \nabla f_t(\mathbf{x}_t), \mathbf{x}_t - \mathbf{x}^* \rangle.
]</p>
</li>
<li>
<p><strong>Bounding the Inner Product</strong></p>
<p>Using the properties of the regularizer and the FTRL updates, we can relate the sum to the Bregman divergence ( D_R ):</p>
<p>[
\sum_{t=1}^T \langle \nabla f_t(\mathbf{x}_t), \mathbf{x}_t - \mathbf{x}^* \rangle \leq \frac{R(\mathbf{x}^*) - R(\mathbf{x}_1)}{\eta}.
]</p>
<p><strong>Bregman Divergence Definition</strong>:</p>
<p>[
D_R(\mathbf{x}, \mathbf{y}) = R(\mathbf{x}) - R(\mathbf{y}) - \langle \nabla R(\mathbf{y}), \mathbf{x} - \mathbf{y} \rangle.
]</p>
</li>
<li>
<p><strong>Regret Bound</strong></p>
<p>Therefore, the total regret is bounded by:</p>
<p>[
\text{Regret}_T \leq \frac{R(\mathbf{x}^*) - R(\mathbf{x}_1)}{\eta}.
]</p>
<p>By choosing ( \eta ) appropriately (e.g., ( \eta = \sqrt{\dfrac{2 [R(\mathbf{x}^*) - R(\mathbf{x}_1)]}{G^2 T}} )), we can achieve a regret bound of:</p>
<p>[
\text{Regret}_T \leq G \sqrt{2 [R(\mathbf{x}^*) - R(\mathbf{x}_1)] T}.
]</p>
</li>
</ol>
<h2 id="online-mirror-descent-omd">Online Mirror Descent (OMD)<a href="#online-mirror-descent-omd" class="hanchor" ariaLabel="Anchor">#</a> </h2>
<h3 id="algorithm-steps">Algorithm Steps<a href="#algorithm-steps" class="hanchor" ariaLabel="Anchor">#</a> </h3>
<ol>
<li>
<p><strong>Initialization</strong>: Choose an initial point ( \mathbf{x}_1 \in \mathcal{X} ).</p>
</li>
<li>
<p><strong>For each round ( t = 1, \dots, T )</strong>:</p>
<p>a. <strong>Compute Subgradient</strong>:</p>
<p>[
\mathbf{g}_t = \nabla f_t(\mathbf{x}_t).
]</p>
<p>b. <strong>Dual Space Update</strong>:</p>
<p>[
\mathbf{z}_{t+1} = \mathbf{z}_t - \eta \mathbf{g}_t,
]</p>
<p>where ( \mathbf{z}_t = \nabla \psi(\mathbf{x}_t) ).</p>
<p>c. <strong>Primal Space Update</strong>:</p>
<p>[
\mathbf{x}<em>{t+1} = \nabla \psi^*(\mathbf{z}</em>{t+1}),
]</p>
<p>with ( \psi^* ) being the convex conjugate of ( \psi ).</p>
</li>
</ol>
<h3 id="regret-analysis-1">Regret Analysis<a href="#regret-analysis-1" class="hanchor" ariaLabel="Anchor">#</a> </h3>
<p><strong>Assumptions</strong></p>
<ol>
<li><strong>Convexity</strong>: Each ( f_t ) is convex.</li>
<li><strong>Lipschitz Continuity</strong>: Subgradients are bounded: ( | \mathbf{g}<em>t |</em>* \leq G ).</li>
<li><strong>Strong Convexity</strong>: The mirror map ( \psi ) is ( \lambda )-strongly convex.</li>
</ol>
<p><strong>Key Steps</strong></p>
<ol>
<li>
<p><strong>Regret Decomposition</strong></p>
<p>The regret can be bounded by:</p>
<p>[
\text{Regret}<em>T \leq \sum</em>{t=1}^T \langle \mathbf{g}_t, \mathbf{x}_t - \mathbf{x}^* \rangle.
]</p>
</li>
<li>
<p><strong>Using Mirror Descent Updates</strong></p>
<p>Utilizing the properties of the Bregman divergence ( D_\psi ) and the mirror descent updates:</p>
<p>[
\sum_{t=1}^T \langle \mathbf{g}<em>t, \mathbf{x}<em>t - \mathbf{x}^* \rangle = \frac{1}{\eta} \left[ D</em>\psi(\mathbf{x}^<em>, \mathbf{x}<em>1) - D</em>\psi(\mathbf{x}^</em>, \mathbf{x}</em>{T+1}) + \sum_{t=1}^T D_\psi(\mathbf{x}_{t+1}, \mathbf{x}_t) \right].
]</p>
</li>
<li>
<p><strong>Bounding the Bregman Divergences</strong></p>
<p>Since ( D_\psi(\mathbf{x}^*, \mathbf{x}<em>{T+1}) \geq 0 ) and ( D</em>\psi(\mathbf{x}_{t+1}, \mathbf{x}_t) \leq \dfrac{\eta^2 G^2}{2 \lambda} ), we have:</p>
<p>[
\text{Regret}<em>T \leq \frac{D</em>\psi(\mathbf{x}^*, \mathbf{x}_1)}{\eta} + \frac{\eta G^2 T}{2 \lambda}.
]</p>
</li>
<li>
<p><strong>Optimizing the Learning Rate</strong></p>
<p>Choosing:</p>
<p>[
\eta = \sqrt{\dfrac{2 \lambda D_\psi(\mathbf{x}^*, \mathbf{x}_1)}{G^2 T}},
]</p>
<p>yields the regret bound:</p>
<p>[
\text{Regret}<em>T \leq G \sqrt{\dfrac{2 D</em>\psi(\mathbf{x}^*, \mathbf{x}_1) T}{\lambda}}.
]</p>
</li>
</ol>
<h2 id="equivalence-of-ftrl-and-omd">Equivalence of FTRL and OMD<a href="#equivalence-of-ftrl-and-omd" class="hanchor" ariaLabel="Anchor">#</a> </h2>
<p>Under certain conditions, FTRL and OMD are equivalent algorithms.</p>
<h3 id="conditions-for-equivalence">Conditions for Equivalence<a href="#conditions-for-equivalence" class="hanchor" ariaLabel="Anchor">#</a> </h3>
<ul>
<li><strong>Matching Regularizers and Mirror Maps</strong>: If the regularizer ( R ) in FTRL is identical to the mirror map ( \psi ) in OMD.</li>
<li><strong>Unconstrained Domain</strong>: When the feasible set ( \mathcal{X} ) is the entire space ( \mathbb{R}^n ).</li>
</ul>
<h3 id="demonstration-of-equivalence">Demonstration of Equivalence<a href="#demonstration-of-equivalence" class="hanchor" ariaLabel="Anchor">#</a> </h3>
<ol>
<li>
<p><strong>FTRL Update in Terms of Gradients</strong></p>
<p>The FTRL update can be expressed as:</p>
<p>[
\mathbf{x}<em>t = \arg\min</em>{\mathbf{x} \in \mathcal{X}} \left{ \left\langle \eta \sum_{s=1}^{t-1} \mathbf{g}_s, \mathbf{x} \right\rangle + R(\mathbf{x}) \right}.
]</p>
</li>
<li>
<p><strong>Relation to Dual Variables in OMD</strong></p>
<p>In OMD, the dual variable ( \mathbf{z}_t ) is:</p>
<p>[
\mathbf{z}_t = \nabla \psi(\mathbf{x}_t) = \mathbf{z}<em>1 - \eta \sum</em>{s=1}^{t-1} \mathbf{g}_s.
]</p>
</li>
<li>
<p><strong>Primal Update via Convex Conjugate</strong></p>
<p>The FTRL update becomes:</p>
<p>[
\mathbf{x}<em>t = \nabla R^*\left( -\eta \sum</em>{s=1}^{t-1} \mathbf{g}_s \right),
]</p>
<p>which matches the OMD update when ( R = \psi ):</p>
<p>[
\mathbf{x}_t = \nabla \psi^*\left( \nabla \psi(\mathbf{x}<em>1) - \eta \sum</em>{s=1}^{t-1} \mathbf{g}_s \right).
]</p>
</li>
</ol>
<h3 id="conclusion">Conclusion<a href="#conclusion" class="hanchor" ariaLabel="Anchor">#</a> </h3>
<p>By aligning the regularization function in FTRL with the mirror map in OMD and considering the unconstrained domain, the updates of both algorithms coincide. This demonstrates that FTRL and OMD are essentially equivalent under these conditions, offering different perspectives on the same optimization process.</p>

      </div></div>

  

  
    

  
</article>

  </div>

  
    <footer class="footer">
  <div class="footer__inner">
    
      <div class="copyright">
        <span>© 2024 Powered by <a href="https://gohugo.io">Hugo</a></span>
    
      <span>:: <a href="https://github.com/panr/hugo-theme-terminal" target="_blank">Theme</a> made by <a href="https://github.com/panr" target="_blank">panr</a></span>
      </div>
  </div>
</footer>






<script type="text/javascript" src="/bundle.min.js"></script>





  
</div>

</body>
</html>
